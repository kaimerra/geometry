{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5273c5-c834-4555-97e2-b3b43e7e4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc09d2-5063-49a0-93d1-f75fbf38d3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075b0fa-c983-455e-a3aa-c464048a7640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd0619-17b4-467d-8ef1-562ced970050",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\n",
    "!wget https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/generate_cow_renders.py\n",
    "from plot_image_grid import image_grid\n",
    "from generate_cow_renders import generate_cow_renders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369e50a-e4bf-452a-b233-5acd7ee5dbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cow_images, _ = generate_cow_renders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba8a71-9c8c-44d7-bbed-0a0976b3d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaigeo import datasets, nerf_models, gan_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2fcbb-3d14-4ad4-98d9-83a6bb45f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgan.models import DCGANDiscriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21ac1e-5c42-4b23-8b0e-652bf4b9c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f10ae3-4b39-4c02-bb24-7de65da88667",
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = datasets.load_session2()\n",
    "session1 = datasets.load_session1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c39bd-6d1f-493b-960f-8fdeb5be1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gan_models.generate_cameras(10).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be390e0-b11c-4b11-b8e0-34e86d2ed840",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_images = torch.concat([session1.target_images, session2.target_images]).to(device)[:, :64, :64][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca8617-99df-4a71-b2e3-1e612842f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_images = cow_images[:, ::2, ::2].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd6eb9-57d8-4a00-bbdd-5f87c69c7fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(target_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c828481-0705-4643-959b-16d20656832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = gan_models.VolumeModel(device).to(device)\n",
    "opt_ls = torch.optim.Adam(ls.parameters(), lr=0.01)#, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba43aee-f95d-48f5-9368-ac7eb1b4882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = DCGANDiscriminator(in_size=64, last_nonlinearity=nn.Sigmoid()).to(device) #Discriminator().to(device)\n",
    "opt_d = torch.optim.Adam(d.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566e48d-7375-4e3f-852a-b32db5b166cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d(target_images[0:1][:, :64, :64].permute(0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0098c1a-1f03-4476-a5d4-1ae687011be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriminator_step():\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    ri = torch.randint(len(target_images), size=(3,))\n",
    "    Y = torch.full((3,), 1.0, dtype=torch.float, device=device)            \n",
    "    y = d(target_images[ri].permute(0, 3, 1, 2))\n",
    "    loss += torch.nn.functional.binary_cross_entropy(y, Y)\n",
    "    \n",
    "    _, rendered = ls.generate(1)\n",
    "    Y = torch.full((1,), 0.0, dtype=torch.float, device=device)\n",
    "    y = d(rendered.permute(0, 3, 1, 2))\n",
    "    loss += torch.nn.functional.binary_cross_entropy(y, Y)\n",
    "\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd0447-9a93-4938-b148-03f90685748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_step():\n",
    "    opt_ls.zero_grad()\n",
    "    density, rendered = ls.generate(10)\n",
    "    Y = torch.full((10,), 1.0, dtype=torch.float, device=device)\n",
    "    y  = d(rendered.permute(0, 3, 1, 2))\n",
    "    mean_density = torch.mean(density)\n",
    "    loss = torch.nn.functional.binary_cross_entropy(y, Y) #- 3.0*mean_density\n",
    "\n",
    "    loss.backward()    \n",
    "    opt_ls.step()\n",
    "\n",
    "    return loss, mean_density, rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8c91c-c945-4c2f-8cf8-063f8aed25cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target_images[22].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9920d6-4957-41fe-afde-02dd40b651e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    d_loss = descriminator_step()    \n",
    "    for _ in range(10):\n",
    "        g_loss, mean_density, rendered = generator_step()\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print('d', d_loss)\n",
    "        print('ls', g_loss)\n",
    "        print('density', mean_density)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff36118-de38-48f7-987c-e4bda808d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rendered.detach().cpu()[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bea88-9e42-41ab-b021-dc6f9a301fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(target_images.detach().cpu()[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6bb93-5460-4e41-bcf7-bc12f707f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(generate_images()[1].detach().cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005649f-d8e2-47f6-8a23-80ce74bd8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(generate_images()[1].detach().cpu()[0])t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34670850-63b5-4ec8-a452-96e332923c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "R, T = look_at_view_transform(\n",
    "    eye = torch.tensor([[0.9, s0.0, 0.0]]), \n",
    "    at = torch.tensor([[0.0, 0.0, 0.0]])\n",
    ")\n",
    "\n",
    "target_cameras = FoVPerspectiveCameras(device=device, R=R, T=T)\n",
    "\n",
    "rendered, _ = renderer_grid(target_cameras, ls.random_gen)\n",
    "rendered = rendered[:, :, :, 1:4]\n",
    "Y = torch.full((1,), 1.0, dtype=torch.float, device=device)\n",
    "y = d(rendered.permute(0, 3, 1, 2)).view(-1)\n",
    "plt.imshow(rendered.detach().cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5ab4e-c77d-42a1-97a0-0ab8197b234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "res, _ = renderer_grid(target_cameras, volumetric_function)\n",
    "loss = torch.nn.functional.mse_loss(res[0][:, :, 1:4], target_image)\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffad4ece-35b5-4e74-8dcd-331af082fefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336321f6-3ee5-400a-a2f9-7b098b67111e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
