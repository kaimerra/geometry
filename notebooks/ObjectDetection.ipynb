{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31112a10-2a1b-4a80-89b4-09475aa0a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f432d-dd35-4da6-9b9c-b625bf7b6029",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b78b0c-7f10-45c5-aa48-c0d80769ba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_video\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn#, FasterRCNN_ResNet50_FPN_Weights\n",
    "import itertools\n",
    "import matplotlib.patches as patches\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95d746-f492-4150-991c-d0b292282a98",
   "metadata": {},
   "source": [
    "# Load Data JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae51f99-3b06-4653-970f-f61f45e7978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = requests.get(\"https://backend.kaimerra.com/feed\")\n",
    "#backend = requests.get(\"http://10.0.3.254:3001/feed\")\n",
    "feed = backend.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc159c1f-bb06-41c4-b44e-fda8846684f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932529ee-10e9-4107-9fad-cbb913fa11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [f for f in feed if 'userName' in f and 'mason' in f['userName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3186a-22c9-47fc-8559-c27c803694a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = feed[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62117b1c-715b-45eb-bc71-33313d8443f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download latest video, save to file\n",
    "#url = z['video_url']\n",
    "#r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "#with open('kaimerra_vid.mkv', 'wb') as f:\n",
    "#    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53694791-ed15-4409-9feb-56b059c34b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43379f6a-108b-4922-a30a-d8d4e0ece434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = torchvision.io.VideoReader('kaimerra_vid.mkv', 'video', num_threads=1)\n",
    "#for d in r:\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d417a3c-bb68-4859-b003-8e7968643a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torchvision.models.detection.ssd300_vgg16(pretrained = True, progress=False).eval()\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679f9e9-9ce6-4bc2-8fcd-f1e4597ea923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaigeo import detect\n",
    "#624df2b8b3c629a0332e53ab\n",
    "objs = detect.detect_for_api(\"62548fb21a2594ec2ebd3040\", model, 'output2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ab585-33f3-4414-87cf-a654db9c2a08",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634edcc-bb9b-4f0a-a2a1-ce1d2620e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaigeo import detect\n",
    "kaigeo.detect_for_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d59a3-cc17-4bd6-9baa-07ad4692dfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(objs[7]['frameImageData']['data'].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d6898-8b86-4c99-b516-452157ce6b34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "objs[7]['x'], objs[7]['width'],\n",
    "\n",
    "objs[7]['y'], objs[7]['height'],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76b2e7-8027-4448-a195-ab88e121422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(objs[o]['extractedImageData']['data'].permute(1, 2, 0).detach().numpy()), objs[5]['category'], objs[7]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660269c-585d-487a-ace2-d529e89a65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load video as torch tensor\n",
    "reader = torchvision.io.VideoReader('kaimerra_vid', \"video\")\n",
    "output = []\n",
    "#reader.seek(2)\n",
    "for frame in reader:#itertools.takewhile(lambda x: x['pts'] <= 5, reader.seek(0)):\n",
    "    output.append(frame['data'])\n",
    "\n",
    "frames = torch.stack(output, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673bbb5-d671-47d4-94bb-a240bff01983",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa6abd-9e9b-4b30-ac96-4ddae88597f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(Frame):\n",
    "    plt.imshow(frames[Frame].permute(1,2,0))\n",
    "    \n",
    "interact(plot_frame, Frame=widgets.IntSlider(min=0, max=len(frames) - 1, step=1,value=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30bd9f-99c3-4351-a5cc-62b46f3d353d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.cm as cm\n",
    "# import matplotlib.animation as animation\n",
    "\n",
    "# fig = plt.figure(figsize = (10,5))\n",
    "# ani_frames = [] # for storing the generated images\n",
    "# # fig, ax = plt.subplots(1,2)\n",
    "# for i in range(len(frames)):\n",
    "#     ani_frames.append([plt.imshow(frames[i].permute(1,2,0).numpy(), cmap=cm.Greys_r,animated=True)])\n",
    "    \n",
    "\n",
    "# ani = animation.ArtistAnimation(fig, ani_frames, interval=30, blit=True,\n",
    "#                                 repeat_delay=0)\n",
    "# # ani.save('movie.mp4')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f506c16-1bef-4b25-bb0e-553b0fb5f955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import convert_image_dtype\n",
    "\n",
    "\n",
    "# model = fasterrcnn_resnet50_fpn(pretrained = True, progress=False)\n",
    "model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(pretrained = True, progress=False)\n",
    "# model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained = True, progress=False)\n",
    "\n",
    "# imgs = convert_image_dtype(frames,dtype=torch.float)\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# outputs = model(frames.float()/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35006675-f052-4ef7-beaf-b08eb6db9dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_box(box):\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    width = box[2] - box[0]\n",
    "    height = box[3] - box[1]\n",
    "    return x,y,width,height\n",
    "\n",
    "def get_extracted_frame(frame,box):\n",
    "    # return frame[:, int(box[0]) : int(box[2]), int(box[1]) : int(box[2])]\n",
    "    return frame[:, int(box[0]) : int(box[2]), int(box[1]) : int(box[3])]\n",
    "\n",
    "def get_annotations(frames,top = 'all'):\n",
    "    annotations={'frame_idx':[],\n",
    "                 'frame':[],\n",
    "                 'extracted_frame':[],\n",
    "                 'category':[], \n",
    "                 'score': [], \n",
    "                 'x':[],\n",
    "                 'y': [], \n",
    "                 'width': [], \n",
    "                 'height': []}\n",
    "    \n",
    "    for frame_idx,frame in enumerate(tqdm(frames)):\n",
    "        outputs = model(frame.unsqueeze(0).float()/255)[0]\n",
    "        labels = [CATEGORY_NAMES[idx] for idx in outputs['labels']]\n",
    "\n",
    "        for object_idx, label in enumerate(labels):\n",
    "            box = outputs['boxes'][object_idx].detach().numpy()\n",
    "            x,y,width,height = get_box(box)\n",
    "            \n",
    "            annotations['frame_idx'].append(frame_idx)\n",
    "            annotations['frame'].append(frames[frame_idx])\n",
    "            annotations['extracted_frame'].append(get_extracted_frame(frames[frame_idx], box))\n",
    "            annotations['category'].append(label)\n",
    "            annotations['score'].append(float(outputs['scores'][object_idx].detach()))\n",
    "            annotations['x'].append(x)\n",
    "            annotations['y'].append(y)\n",
    "            annotations['width'].append(width)\n",
    "            annotations['height'].append(height)\n",
    "            \n",
    "    if top == 'all':\n",
    "        return annotations\n",
    "    \n",
    "    elif isinstance(top,int):\n",
    "        top_indices = np.argpartition(annotations['score'], -top)[-top:]\n",
    "        annotations_top = {'frame_idx':[annotations['frame_idx'][idx] for idx in top_indices],\n",
    "                           'frame':[annotations['frame'][idx] for idx in top_indices],\n",
    "                           'extracted_frame':[annotations['extracted_frame'][idx] for idx in top_indices],\n",
    "                           'category':[annotations['category'][idx] for idx in top_indices], \n",
    "                           'score': [annotations['score'][idx] for idx in top_indices], \n",
    "                           'x':[annotations['x'][idx] for idx in top_indices], \n",
    "                           'y': [annotations['y'][idx] for idx in top_indices], \n",
    "                           'width': [annotations['width'][idx] for idx in top_indices], \n",
    "                           'height': [annotations['height'][idx] for idx in top_indices]}\n",
    "\n",
    "        return annotations_top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9d8558-3f0a-4f31-b4b5-3231266a74aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations = get_annotations(frames, top = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49e4d1-e432-4807-9318-186a65dc0195",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(annotations['extracted_frame'][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa9a51-f471-4788-a54b-7b60912dfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(annotations['frame_idx']),figsize = (10,10 * len(annotations['frame_idx'])))\n",
    "\n",
    "for frame_idx,frame in enumerate(annotations['frame_idx']):\n",
    "    ax[frame_idx].imshow(frames[frame].permute(1,2,0))\n",
    "    \n",
    "    # xy, width, height = get_box(annotations['Bounding Box'][frame_idx])\n",
    "    rectangle = patches.Rectangle(xy = [annotations['x'][frame_idx],annotations['y'][frame_idx]],\n",
    "                                  width = annotations['width'][frame_idx],\n",
    "                                  height = annotations['height'][frame_idx],\n",
    "                                  linewidth=3, edgecolor='r', facecolor='none')\n",
    "    ax[frame_idx].add_patch(rectangle)\n",
    "    # ax[frame_idx].set_title(annotations['category'][frame_idx])\n",
    "    ax[frame_idx].text(annotations['x'][frame_idx], annotations['y'][frame_idx]-30, annotations['category'][frame_idx], color='red', bbox=dict(facecolor='white', edgecolor='red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bf678-2ec0-4f14-909d-8419be53d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccab19-4298-46ac-86c1-1a3c8f22b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frames[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b924d19-cfed-48f9-af7c-6f019f58f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_snippet = frame[:,12:1270,20:709]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af65b2f-b9f4-47d8-a225-cb520b0981cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame_snippet.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c29bd3-02ed-49f4-9622-d51c80108fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['boxes'][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06336746-f109-4ec1-8173-1ff4ce3d363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = sum([model(five_frames.float()/255) for five_frames in chunker(frames,5)],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e8673-d577-48c4-8f7b-f6e8a01b7676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_threshold = 0.6\n",
    "\n",
    "# label_idxs = [[label for label in output['labels'][(output['scores'] > score_threshold).nonzero()]]for output in outputs]\n",
    "# labels = [[CATEGORY_NAMES[idx] for idx in label_idx] for label_idx in label_idxs]\n",
    "# boxes = [[box[0] for box in output['boxes'][(output['scores'] > score_threshold).nonzero()]]for output in outputs]\n",
    "\n",
    "# score_indices = np.arange(0,5) #The scores are listed in order, so the 0th score was the top scoring bounding box\n",
    "# label_idxs = [[output['labels'][score_idx] for output in outputs] for score_idx in score_indices]\n",
    "# labels = [[CATEGORY_NAMES[idx] for idx in label_idx] for label_idx in label_idxs]\n",
    "# boxes = [[output['boxes'][score_idx] for output in outputs] for score_idx in score_indices]\n",
    "\n",
    "def get_box(box):\n",
    "    xy = box[0:2]\n",
    "    width = box[2] - box[0]\n",
    "    height = box[3] - box[1]\n",
    "    return xy.detach().numpy(), width.detach().numpy(), height.detach().numpy()\n",
    "    \n",
    "fig, ax = plt.subplots(2,figsize = (10,10 * len(outputs)))\n",
    "for frame_idx,frame in enumerate(frames):\n",
    "    ax[frame_idx].imshow(frame.permute(1,2,0))\n",
    "    \n",
    "    for box_idx,box in enumerate(boxes[frame_idx]):\n",
    "        xy, width, height = get_box(box)\n",
    "        rectangle = patches.Rectangle(xy = xy,\n",
    "                                      width = width,\n",
    "                                      height = height,\n",
    "                                      linewidth=3, edgecolor='r', facecolor='none')\n",
    "        ax[frame_idx].add_patch(rectangle)\n",
    "        # ax[idx].set_title(labels[idx])\n",
    "        ax[frame_idx].text(xy[0], xy[1]-30, labels[frame_idx][box_idx], color='red', \n",
    "        bbox=dict(facecolor='white', edgecolor='red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5b7a5-70b5-417d-9f18-5544f6289612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416bbd32-5391-4513-8dc2-33217624248c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
